Warning: Unsupported TensorFlow Lite semantics for QUANTIZE 'tfl.quantize'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: serving_default_input.1:0
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_1'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_2'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for PADV2 'PadV2'. Placing on CPU instead
 - Scalar Input tensors are only valid for op type: ADD, EXPAND_DIMS, MAXIMUM, MEAN, MINIMUM, MUL, QUANTIZE, SPLIT, SPLIT_V, SUB
   Op has scalar input tensor(s): PadV2/constant_values
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_3'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_4'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_6'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_7'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_9'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_10'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_12'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_13'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_15'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_16'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_18'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_19'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_21'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_25'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_27'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_28'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_30'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_31'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_33'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_34'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_36'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_40'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_42'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_43'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_45'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_46'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_48'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_49'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_51'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_55'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_57'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_58'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_60'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_61'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for MEAN 'Mean'. Placing on CPU instead
 - Axis indices must correspond to height and width axes
   Axis is [2, 3]
Warning: Unsupported TensorFlow Lite semantics for DEQUANTIZE 'StatefulPartitionedCall:0'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: StatefulPartitionedCall:0
Warning: Mean operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: PadV2 operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Quantize operation is unknown or unsupported, placing on CPU
<nng.Tensor 'MaxPool2d' shape=[1, 56, 56, 64] dtype=int8> adding consumer <nng.Operation 'transpose_4' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_4' type=Transpose>
<nng.Tensor 'transpose_4' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'call_main_split_4' type=CustomNpuOp>
<nng.Tensor 'Pad_1' shape=[1, 64, 58, 58] dtype=int8> adding consumer <nng.Operation 'transpose_6' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_6' type=Transpose>
<nng.Tensor 'transpose_6' shape=[1, 58, 58, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_5' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_4;Add_1;convolution_4;convolution_1;Const_39' shape=[1, 56, 56, 64] dtype=int8> adding consumer <nng.Operation 'transpose_7' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_7' type=Transpose>
<nng.Tensor 'transpose_7' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'call_main_split_6' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_7;onnx_tf_prefix_Add_6' shape=[1, 56, 56, 64] dtype=int8> adding consumer <nng.Operation 'transpose_10' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_10' type=Transpose>
<nng.Tensor 'transpose_10' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'call_main_split_8' type=CustomNpuOp>
<nng.Tensor 'Pad_3' shape=[1, 64, 58, 58] dtype=int8> adding consumer <nng.Operation 'transpose_12' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_12' type=Transpose>
<nng.Tensor 'transpose_12' shape=[1, 58, 58, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_9' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_9;Add_3;convolution_4;convolution_3;Const_35' shape=[1, 56, 56, 64] dtype=int8> adding consumer <nng.Operation 'transpose_13' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_13' type=Transpose>
<nng.Tensor 'transpose_13' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'call_main_split_10' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_12;onnx_tf_prefix_Add_11' shape=[1, 56, 56, 64] dtype=int8> adding consumer <nng.Operation 'transpose_16' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_16' type=Transpose>
<nng.Tensor 'transpose_16' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'call_main_split_12' type=CustomNpuOp>
<nng.Tensor 'Pad_5' shape=[1, 64, 58, 58] dtype=int8> adding consumer <nng.Operation 'transpose_18' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_18' type=Transpose>
<nng.Tensor 'transpose_18' shape=[1, 58, 58, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_13' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_14;Add_5;convolution_9;convolution_5;Const_31' shape=[1, 28, 28, 128] dtype=int8> adding consumer <nng.Operation 'transpose_19' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_19' type=Transpose>
<nng.Tensor 'transpose_19' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'call_main_split_14' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_18;onnx_tf_prefix_Add_17' shape=[1, 28, 28, 128] dtype=int8> adding consumer <nng.Operation 'transpose_25' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_25' type=Transpose>
<nng.Tensor 'transpose_25' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'call_main_split_16' type=CustomNpuOp>
<nng.Tensor 'Pad_7' shape=[1, 128, 30, 30] dtype=int8> adding consumer <nng.Operation 'transpose_27' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_27' type=Transpose>
<nng.Tensor 'transpose_27' shape=[1, 30, 30, 128] dtype=int8> adding consumer <nng.Operation 'call_main_split_17' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_20;Add_8;convolution_9;convolution_8;Const_25' shape=[1, 28, 28, 128] dtype=int8> adding consumer <nng.Operation 'transpose_28' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_28' type=Transpose>
<nng.Tensor 'transpose_28' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'call_main_split_18' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_23;onnx_tf_prefix_Add_22' shape=[1, 28, 28, 128] dtype=int8> adding consumer <nng.Operation 'transpose_31' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_31' type=Transpose>
<nng.Tensor 'transpose_31' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'call_main_split_20' type=CustomNpuOp>
<nng.Tensor 'Pad_9' shape=[1, 128, 30, 30] dtype=int8> adding consumer <nng.Operation 'transpose_33' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_33' type=Transpose>
<nng.Tensor 'transpose_33' shape=[1, 30, 30, 128] dtype=int8> adding consumer <nng.Operation 'call_main_split_21' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_25;Add_10;convolution_14;convolution_10;Const_21' shape=[1, 14, 14, 256] dtype=int8> adding consumer <nng.Operation 'transpose_34' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_34' type=Transpose>
<nng.Tensor 'transpose_34' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'call_main_split_22' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_29;onnx_tf_prefix_Add_28' shape=[1, 14, 14, 256] dtype=int8> adding consumer <nng.Operation 'transpose_40' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_40' type=Transpose>
<nng.Tensor 'transpose_40' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'call_main_split_24' type=CustomNpuOp>
<nng.Tensor 'Pad_11' shape=[1, 256, 16, 16] dtype=int8> adding consumer <nng.Operation 'transpose_42' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_42' type=Transpose>
<nng.Tensor 'transpose_42' shape=[1, 16, 16, 256] dtype=int8> adding consumer <nng.Operation 'call_main_split_25' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_31;Add_13;convolution_14;convolution_13;Const_15' shape=[1, 14, 14, 256] dtype=int8> adding consumer <nng.Operation 'transpose_43' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_43' type=Transpose>
<nng.Tensor 'transpose_43' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'call_main_split_26' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_34;onnx_tf_prefix_Add_33' shape=[1, 14, 14, 256] dtype=int8> adding consumer <nng.Operation 'transpose_46' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_46' type=Transpose>
<nng.Tensor 'transpose_46' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'call_main_split_28' type=CustomNpuOp>
<nng.Tensor 'Pad_13' shape=[1, 256, 16, 16] dtype=int8> adding consumer <nng.Operation 'transpose_48' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_48' type=Transpose>
<nng.Tensor 'transpose_48' shape=[1, 16, 16, 256] dtype=int8> adding consumer <nng.Operation 'call_main_split_29' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_36;Add_15;convolution_19;convolution_15;Const_11' shape=[1, 7, 7, 512] dtype=int8> adding consumer <nng.Operation 'transpose_49' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_49' type=Transpose>
<nng.Tensor 'transpose_49' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'call_main_split_30' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_40;onnx_tf_prefix_Add_39' shape=[1, 7, 7, 512] dtype=int8> adding consumer <nng.Operation 'transpose_55' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_55' type=Transpose>
<nng.Tensor 'transpose_55' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'call_main_split_32' type=CustomNpuOp>
<nng.Tensor 'Pad_15' shape=[1, 512, 9, 9] dtype=int8> adding consumer <nng.Operation 'transpose_57' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_57' type=Transpose>
<nng.Tensor 'transpose_57' shape=[1, 9, 9, 512] dtype=int8> adding consumer <nng.Operation 'call_main_split_33' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_42;Add_18;convolution_19;convolution_18;Const_5' shape=[1, 7, 7, 512] dtype=int8> adding consumer <nng.Operation 'transpose_58' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_58' type=Transpose>
<nng.Tensor 'transpose_58' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'call_main_split_34' type=CustomNpuOp>
<nng.Tensor 'transpose_4_npu' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'Pad_1_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_1_right_0_npu' shape=[1, 64, 56, 1] dtype=int8> adding consumer <nng.Operation 'Pad_1_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_7_npu' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'Pad_2_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_2_right_0_npu' shape=[1, 64, 56, 1] dtype=int8> adding consumer <nng.Operation 'Pad_2_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_10_npu' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'Pad_3_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_3_right_0_npu' shape=[1, 64, 56, 1] dtype=int8> adding consumer <nng.Operation 'Pad_3_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_13_npu' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'Pad_4_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_4_right_0_npu' shape=[1, 64, 56, 1] dtype=int8> adding consumer <nng.Operation 'Pad_4_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_16_npu' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'Pad_5_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_5_right_0_npu' shape=[1, 64, 56, 1] dtype=int8> adding consumer <nng.Operation 'Pad_5_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_19_npu' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'Pad_6_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_6_right_0_npu' shape=[1, 128, 28, 1] dtype=int8> adding consumer <nng.Operation 'Pad_6_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_25_npu' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'Pad_7_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_7_right_0_npu' shape=[1, 128, 28, 1] dtype=int8> adding consumer <nng.Operation 'Pad_7_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_28_npu' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'Pad_8_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_8_right_0_npu' shape=[1, 128, 28, 1] dtype=int8> adding consumer <nng.Operation 'Pad_8_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_31_npu' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'Pad_9_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_9_right_0_npu' shape=[1, 128, 28, 1] dtype=int8> adding consumer <nng.Operation 'Pad_9_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_34_npu' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'Pad_10_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_10_right_0_npu' shape=[1, 256, 14, 1] dtype=int8> adding consumer <nng.Operation 'Pad_10_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_40_npu' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'Pad_11_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_11_right_0_npu' shape=[1, 256, 14, 1] dtype=int8> adding consumer <nng.Operation 'Pad_11_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_43_npu' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'Pad_12_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_12_right_0_npu' shape=[1, 256, 14, 1] dtype=int8> adding consumer <nng.Operation 'Pad_12_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_46_npu' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'Pad_13_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_13_right_0_npu' shape=[1, 256, 14, 1] dtype=int8> adding consumer <nng.Operation 'Pad_13_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_49_npu' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'Pad_14_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_14_right_0_npu' shape=[1, 512, 7, 1] dtype=int8> adding consumer <nng.Operation 'Pad_14_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_55_npu' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'Pad_15_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_15_right_0_npu' shape=[1, 512, 7, 1] dtype=int8> adding consumer <nng.Operation 'Pad_15_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_58_npu' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'Pad_16_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_16_right_0_npu' shape=[1, 512, 7, 1] dtype=int8> adding consumer <nng.Operation 'Pad_16_concat2_avgpool' type=AvgPool>

Network summary for person_attr_resnet_v1_18_quant
Accelerator configuration               Ethos_U65_256
System configuration                 internal-default
Memory mode                          internal-default
Accelerator clock                                1000 MHz
Design peak SRAM bandwidth                      16.00 GB/s
Design peak DRAM bandwidth                       3.75 GB/s

Total SRAM used                                378.67 KiB
Total DRAM used                              11492.47 KiB

CPU operators = 16 (16.5%)
NPU operators = 81 (83.5%)

Average SRAM bandwidth                           0.80 GB/s
Input   SRAM bandwidth                           0.70 MB/batch
Weight  SRAM bandwidth                          35.66 MB/batch
Output  SRAM bandwidth                           0.00 MB/batch
Total   SRAM bandwidth                          36.41 MB/batch
Total   SRAM bandwidth            per input     36.41 MB/inference (batch size 1)

Average DRAM bandwidth                           0.80 GB/s
Input   DRAM bandwidth                          16.65 MB/batch
Weight  DRAM bandwidth                           9.91 MB/batch
Output  DRAM bandwidth                           9.68 MB/batch
Total   DRAM bandwidth                          36.25 MB/batch
Total   DRAM bandwidth            per input     36.25 MB/inference (batch size 1)

Neural network macs                        1821633220 MACs/batch
Network Tops/s                                   0.08 Tops/s

NPU cycles                                   21684188 cycles/batch
SRAM Access cycles                              87808 cycles/batch
DRAM Access cycles                           44270585 cycles/batch
On-chip Flash Access cycles                         0 cycles/batch
Off-chip Flash Access cycles                        0 cycles/batch
Total cycles                                 45236592 cycles/batch

Batch Inference time                45.24 ms,   22.11 inferences/s (batch size 1)

