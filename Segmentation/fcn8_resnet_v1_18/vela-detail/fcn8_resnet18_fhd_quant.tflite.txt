Warning: Unsupported TensorFlow Lite semantics for QUANTIZE 'tfl.quantize'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: serving_default_input:0
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_1'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_2'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for PADV2 'PadV2'. Placing on CPU instead
 - Scalar Input tensors are only valid for op type: ADD, EXPAND_DIMS, MAXIMUM, MEAN, MINIMUM, MUL, QUANTIZE, SPLIT, SPLIT_V, SUB
   Op has scalar input tensor(s): PadV2/constant_values
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_3'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_4'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_6'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_7'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_9'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_10'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_12'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_13'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_15'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_16'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_18'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_19'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_21'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_25'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_27'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_28'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_30'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_31'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_33'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_34'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_36'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_40'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_42'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_43'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_45'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_46'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_48'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_49'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_51'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_55'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_57'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_58'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_60'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_67'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'onnx_tf_prefix_BatchNormalization_48/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_73'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'onnx_tf_prefix_BatchNormalization_52/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_80'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for ARG_MAX 'onnx_tf_prefix_ArgMax_73'. Placing on CPU instead
 - Scalar Input tensors are only valid for op type: ADD, EXPAND_DIMS, MAXIMUM, MEAN, MINIMUM, MUL, QUANTIZE, SPLIT, SPLIT_V, SUB
   Op has scalar input tensor(s): Rank
Warning: Unsupported TensorFlow Lite semantics for RESHAPE 'PartitionedCall:0'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: onnx_tf_prefix_ArgMax_73, PartitionedCall:0
Warning: RESIZE_BILINEAR 'ResizeBilinear' is not supported on the NPU. Placing on CPU instead
 - The width and height of the IFM and OFM must match one of the following criteria:
        IFM W and H must both be 1
        IFM must match OFM
        W and H scaling must be equal and OFM W-1 and H-1 must be 2x/4x/8x IFM W-1 and H-1, if align_corners is True
        W and H scaling must be equal and OFM W and H must be 2x/4x/8x IFM W and H, if align_corners is False
   Op has ifm_shape=[1, 128, 240, 19], ofm_shape=[1, 1024, 1920, 19] and align_corners=True
Warning: ArgMax operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: ResizeBilinear operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: PadV2 operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Quantize operation is unknown or unsupported, placing on CPU
<nng.Tensor 'MaxPool2d' shape=[1, 256, 480, 64] dtype=int8> adding consumer <nng.Operation 'transpose_4' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_4' type=Transpose>
<nng.Tensor 'transpose_4' shape=[1, 64, 256, 480] dtype=int8> adding consumer <nng.Operation 'call_main_split_4' type=CustomNpuOp>
<nng.Tensor 'Pad_1' shape=[1, 64, 258, 482] dtype=int8> adding consumer <nng.Operation 'transpose_6' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_6' type=Transpose>
<nng.Tensor 'transpose_6' shape=[1, 258, 482, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_5' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_4;Add_1;convolution_4;convolution_1;Const_56' shape=[1, 256, 480, 64] dtype=int8> adding consumer <nng.Operation 'transpose_7' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_7' type=Transpose>
<nng.Tensor 'transpose_7' shape=[1, 64, 256, 480] dtype=int8> adding consumer <nng.Operation 'call_main_split_6' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_7;onnx_tf_prefix_Add_6' shape=[1, 256, 480, 64] dtype=int8> adding consumer <nng.Operation 'transpose_10' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_10' type=Transpose>
<nng.Tensor 'transpose_10' shape=[1, 64, 256, 480] dtype=int8> adding consumer <nng.Operation 'call_main_split_8' type=CustomNpuOp>
<nng.Tensor 'Pad_3' shape=[1, 64, 258, 482] dtype=int8> adding consumer <nng.Operation 'transpose_12' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_12' type=Transpose>
<nng.Tensor 'transpose_12' shape=[1, 258, 482, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_9' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_9;Add_3;convolution_4;convolution_3;Const_52' shape=[1, 256, 480, 64] dtype=int8> adding consumer <nng.Operation 'transpose_13' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_13' type=Transpose>
<nng.Tensor 'transpose_13' shape=[1, 64, 256, 480] dtype=int8> adding consumer <nng.Operation 'call_main_split_10' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_12;onnx_tf_prefix_Add_11' shape=[1, 256, 480, 64] dtype=int8> adding consumer <nng.Operation 'transpose_16' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_16' type=Transpose>
<nng.Tensor 'transpose_16' shape=[1, 64, 256, 480] dtype=int8> adding consumer <nng.Operation 'call_main_split_12' type=CustomNpuOp>
<nng.Tensor 'Pad_5' shape=[1, 64, 258, 482] dtype=int8> adding consumer <nng.Operation 'transpose_18' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_18' type=Transpose>
<nng.Tensor 'transpose_18' shape=[1, 258, 482, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_13' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_14;Add_5;convolution_9;convolution_5;Const_48' shape=[1, 128, 240, 128] dtype=int8> adding consumer <nng.Operation 'transpose_19' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_19' type=Transpose>
<nng.Tensor 'transpose_19' shape=[1, 128, 128, 240] dtype=int8> adding consumer <nng.Operation 'call_main_split_14' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_18;onnx_tf_prefix_Add_17' shape=[1, 128, 240, 128] dtype=int8> adding consumer <nng.Operation 'transpose_25' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_25' type=Transpose>
<nng.Tensor 'transpose_25' shape=[1, 128, 128, 240] dtype=int8> adding consumer <nng.Operation 'call_main_split_16' type=CustomNpuOp>
<nng.Tensor 'Pad_7' shape=[1, 128, 130, 242] dtype=int8> adding consumer <nng.Operation 'transpose_27' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_27' type=Transpose>
<nng.Tensor 'transpose_27' shape=[1, 130, 242, 128] dtype=int8> adding consumer <nng.Operation 'call_main_split_17' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_20;Add_8;convolution_9;convolution_8;Const_42' shape=[1, 128, 240, 128] dtype=int8> adding consumer <nng.Operation 'transpose_28' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_28' type=Transpose>
<nng.Tensor 'transpose_28' shape=[1, 128, 128, 240] dtype=int8> adding consumer <nng.Operation 'call_main_split_18' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_23;onnx_tf_prefix_Add_22' shape=[1, 128, 240, 128] dtype=int8> adding consumer <nng.Operation 'transpose_31' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_31' type=Transpose>
<nng.Tensor 'transpose_31' shape=[1, 128, 128, 240] dtype=int8> adding consumer <nng.Operation 'call_main_split_20' type=CustomNpuOp>
<nng.Tensor 'Pad_9' shape=[1, 128, 130, 242] dtype=int8> adding consumer <nng.Operation 'transpose_33' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_33' type=Transpose>
<nng.Tensor 'transpose_33' shape=[1, 130, 242, 128] dtype=int8> adding consumer <nng.Operation 'call_main_split_21' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_25;Add_10;convolution_14;convolution_10;Const_38' shape=[1, 64, 120, 256] dtype=int8> adding consumer <nng.Operation 'transpose_34' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_34' type=Transpose>
<nng.Tensor 'transpose_34' shape=[1, 256, 64, 120] dtype=int8> adding consumer <nng.Operation 'call_main_split_22' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_29;onnx_tf_prefix_Add_28' shape=[1, 64, 120, 256] dtype=int8> adding consumer <nng.Operation 'transpose_40' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_40' type=Transpose>
<nng.Tensor 'transpose_40' shape=[1, 256, 64, 120] dtype=int8> adding consumer <nng.Operation 'call_main_split_24' type=CustomNpuOp>
<nng.Tensor 'Pad_11' shape=[1, 256, 66, 122] dtype=int8> adding consumer <nng.Operation 'transpose_42' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_42' type=Transpose>
<nng.Tensor 'transpose_42' shape=[1, 66, 122, 256] dtype=int8> adding consumer <nng.Operation 'call_main_split_25' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_31;Add_13;convolution_14;convolution_13;Const_32' shape=[1, 64, 120, 256] dtype=int8> adding consumer <nng.Operation 'transpose_43' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_43' type=Transpose>
<nng.Tensor 'transpose_43' shape=[1, 256, 64, 120] dtype=int8> adding consumer <nng.Operation 'call_main_split_26' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_34;onnx_tf_prefix_Add_33' shape=[1, 64, 120, 256] dtype=int8> adding consumer <nng.Operation 'transpose_46' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_46' type=Transpose>
<nng.Tensor 'transpose_46' shape=[1, 256, 64, 120] dtype=int8> adding consumer <nng.Operation 'call_main_split_28' type=CustomNpuOp>
<nng.Tensor 'Pad_13' shape=[1, 256, 66, 122] dtype=int8> adding consumer <nng.Operation 'transpose_48' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_48' type=Transpose>
<nng.Tensor 'transpose_48' shape=[1, 66, 122, 256] dtype=int8> adding consumer <nng.Operation 'call_main_split_29' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_36;Add_15;convolution_19;convolution_15;Const_28' shape=[1, 32, 60, 512] dtype=int8> adding consumer <nng.Operation 'transpose_49' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_49' type=Transpose>
<nng.Tensor 'transpose_49' shape=[1, 512, 32, 60] dtype=int8> adding consumer <nng.Operation 'call_main_split_30' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_40;onnx_tf_prefix_Add_39' shape=[1, 32, 60, 512] dtype=int8> adding consumer <nng.Operation 'transpose_55' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_55' type=Transpose>
<nng.Tensor 'transpose_55' shape=[1, 512, 32, 60] dtype=int8> adding consumer <nng.Operation 'call_main_split_32' type=CustomNpuOp>
<nng.Tensor 'Pad_15' shape=[1, 512, 34, 62] dtype=int8> adding consumer <nng.Operation 'transpose_57' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_57' type=Transpose>
<nng.Tensor 'transpose_57' shape=[1, 34, 62, 512] dtype=int8> adding consumer <nng.Operation 'call_main_split_33' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_Relu_42;Add_18;convolution_19;convolution_18;Const_22' shape=[1, 32, 60, 512] dtype=int8> adding consumer <nng.Operation 'transpose_58' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_58' type=Transpose>
<nng.Tensor 'transpose_58' shape=[1, 512, 32, 60] dtype=int8> adding consumer <nng.Operation 'call_main_split_34' type=CustomNpuOp>
<nng.Tensor 'transpose_4_npu' shape=[1, 64, 256, 480] dtype=int8> adding consumer <nng.Operation 'Pad_1_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_1_right_0_npu' shape=[1, 64, 256, 1] dtype=int8> adding consumer <nng.Operation 'Pad_1_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_7_npu' shape=[1, 64, 256, 480] dtype=int8> adding consumer <nng.Operation 'Pad_2_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_2_right_0_npu' shape=[1, 64, 256, 1] dtype=int8> adding consumer <nng.Operation 'Pad_2_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_10_npu' shape=[1, 64, 256, 480] dtype=int8> adding consumer <nng.Operation 'Pad_3_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_3_right_0_npu' shape=[1, 64, 256, 1] dtype=int8> adding consumer <nng.Operation 'Pad_3_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_13_npu' shape=[1, 64, 256, 480] dtype=int8> adding consumer <nng.Operation 'Pad_4_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_4_right_0_npu' shape=[1, 64, 256, 1] dtype=int8> adding consumer <nng.Operation 'Pad_4_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_16_npu' shape=[1, 64, 256, 480] dtype=int8> adding consumer <nng.Operation 'Pad_5_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_5_right_0_npu' shape=[1, 64, 256, 1] dtype=int8> adding consumer <nng.Operation 'Pad_5_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_19_npu' shape=[1, 128, 128, 240] dtype=int8> adding consumer <nng.Operation 'Pad_6_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_6_right_0_npu' shape=[1, 128, 128, 1] dtype=int8> adding consumer <nng.Operation 'Pad_6_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_25_npu' shape=[1, 128, 128, 240] dtype=int8> adding consumer <nng.Operation 'Pad_7_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_7_right_0_npu' shape=[1, 128, 128, 1] dtype=int8> adding consumer <nng.Operation 'Pad_7_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_28_npu' shape=[1, 128, 128, 240] dtype=int8> adding consumer <nng.Operation 'Pad_8_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_8_right_0_npu' shape=[1, 128, 128, 1] dtype=int8> adding consumer <nng.Operation 'Pad_8_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_31_npu' shape=[1, 128, 128, 240] dtype=int8> adding consumer <nng.Operation 'Pad_9_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_9_right_0_npu' shape=[1, 128, 128, 1] dtype=int8> adding consumer <nng.Operation 'Pad_9_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_34_npu' shape=[1, 256, 64, 120] dtype=int8> adding consumer <nng.Operation 'Pad_10_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_10_right_0_npu' shape=[1, 256, 64, 1] dtype=int8> adding consumer <nng.Operation 'Pad_10_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_40_npu' shape=[1, 256, 64, 120] dtype=int8> adding consumer <nng.Operation 'Pad_11_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_11_right_0_npu' shape=[1, 256, 64, 1] dtype=int8> adding consumer <nng.Operation 'Pad_11_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_43_npu' shape=[1, 256, 64, 120] dtype=int8> adding consumer <nng.Operation 'Pad_12_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_12_right_0_npu' shape=[1, 256, 64, 1] dtype=int8> adding consumer <nng.Operation 'Pad_12_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_46_npu' shape=[1, 256, 64, 120] dtype=int8> adding consumer <nng.Operation 'Pad_13_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_13_right_0_npu' shape=[1, 256, 64, 1] dtype=int8> adding consumer <nng.Operation 'Pad_13_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_49_npu' shape=[1, 512, 32, 60] dtype=int8> adding consumer <nng.Operation 'Pad_14_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_14_right_0_npu' shape=[1, 512, 32, 1] dtype=int8> adding consumer <nng.Operation 'Pad_14_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_55_npu' shape=[1, 512, 32, 60] dtype=int8> adding consumer <nng.Operation 'Pad_15_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_15_right_0_npu' shape=[1, 512, 32, 1] dtype=int8> adding consumer <nng.Operation 'Pad_15_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_58_npu' shape=[1, 512, 32, 60] dtype=int8> adding consumer <nng.Operation 'Pad_16_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_16_right_0_npu' shape=[1, 512, 32, 1] dtype=int8> adding consumer <nng.Operation 'Pad_16_concat2_avgpool' type=AvgPool>

Network summary for fcn8_resnet18_fhd_quant
Accelerator configuration               Ethos_U65_256
System configuration                 internal-default
Memory mode                          internal-default
Accelerator clock                                1000 MHz
Design peak SRAM bandwidth                      16.00 GB/s
Design peak DRAM bandwidth                       3.75 GB/s

Total SRAM used                                370.91 KiB
Total DRAM used                              83090.38 KiB

CPU operators = 21 (18.4%)
NPU operators = 93 (81.6%)

Average SRAM bandwidth                           0.52 GB/s
Input   SRAM bandwidth                           1.68 MB/batch
Weight  SRAM bandwidth                         859.53 MB/batch
Output  SRAM bandwidth                           0.00 MB/batch
Total   SRAM bandwidth                         861.26 MB/batch
Total   SRAM bandwidth            per input    861.26 MB/inference (batch size 1)

Average DRAM bandwidth                           0.61 GB/s
Input   DRAM bandwidth                         628.90 MB/batch
Weight  DRAM bandwidth                           9.76 MB/batch
Output  DRAM bandwidth                         360.26 MB/batch
Total   DRAM bandwidth                         998.91 MB/batch
Total   DRAM bandwidth            per input    998.91 MB/inference (batch size 1)

Neural network macs                       71711747780 MACs/batch
Network Tops/s                                   0.09 Tops/s

NPU cycles                                  666429368 cycles/batch
SRAM Access cycles                             159528 cycles/batch
DRAM Access cycles                         1638439790 cycles/batch
On-chip Flash Access cycles                         0 cycles/batch
Off-chip Flash Access cycles                        0 cycles/batch
Total cycles                               1643542620 cycles/batch

Batch Inference time              1643.54 ms,    0.61 inferences/s (batch size 1)

