Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_1'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_8'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_10'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_20'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_22'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_32'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_34'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_41'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_43'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_50'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_52'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_59'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_61'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_71'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_73'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_80'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_82'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_89'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_91'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_98'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_100'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_107'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_109'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_116'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_118'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_125'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_127'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_131'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_101/perm
Warning: Unsupported TensorFlow Lite semantics for MEAN 'Mean'. Placing on CPU instead
 - Axis indices must correspond to height and width axes
   Axis is [2, 3]
Warning: Mean operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
<nng.Tensor 'onnx_tf_prefix_/s1/b1/f/a_relu/Relu;Add_2;convolution_6;convolution_2;Const_84' shape=[1, 112, 112, 24] dtype=int8> adding consumer <nng.Operation 'transpose_8' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_8' type=Transpose>
<nng.Tensor 'transpose_8' shape=[1, 24, 112, 112] dtype=int8> adding consumer <nng.Operation 'call_main_split_3' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_/s2/b1/f/a_relu/Relu;Add_6;convolution_16;convolution_8;Const_76' shape=[1, 56, 56, 56] dtype=int8> adding consumer <nng.Operation 'transpose_20' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_20' type=Transpose>
<nng.Tensor 'transpose_20' shape=[1, 56, 56, 56] dtype=int8> adding consumer <nng.Operation 'call_main_split_5' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_/s3/b1/f/a_relu/Relu;Add_10;convolution_101;convolution_18;Const_68' shape=[1, 28, 28, 152] dtype=int8> adding consumer <nng.Operation 'transpose_32' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_32' type=Transpose>
<nng.Tensor 'transpose_32' shape=[1, 152, 28, 28] dtype=int8> adding consumer <nng.Operation 'call_main_split_7' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_/s3/b2/f/a_relu/Relu;Add_13;convolution_101;convolution_39;Const_62' shape=[1, 14, 14, 152] dtype=int8> adding consumer <nng.Operation 'transpose_41' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_41' type=Transpose>
<nng.Tensor 'transpose_41' shape=[1, 152, 14, 14] dtype=int8> adding consumer <nng.Operation 'call_main_split_9' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_/s3/b3/f/a_relu/Relu;Add_16;convolution_101;convolution_60;Const_56' shape=[1, 14, 14, 152] dtype=int8> adding consumer <nng.Operation 'transpose_50' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_50' type=Transpose>
<nng.Tensor 'transpose_50' shape=[1, 152, 14, 14] dtype=int8> adding consumer <nng.Operation 'call_main_split_11' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_/s3/b4/f/a_relu/Relu;Add_19;convolution_101;convolution_81;Const_50' shape=[1, 14, 14, 152] dtype=int8> adding consumer <nng.Operation 'transpose_59' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_59' type=Transpose>
<nng.Tensor 'transpose_59' shape=[1, 152, 14, 14] dtype=int8> adding consumer <nng.Operation 'call_main_split_13' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_/s4/b1/f/a_relu/Relu;Add_23;convolution_438;convolution_103;Const_42' shape=[1, 14, 14, 368] dtype=int8> adding consumer <nng.Operation 'transpose_71' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_71' type=Transpose>
<nng.Tensor 'transpose_71' shape=[1, 368, 14, 14] dtype=int8> adding consumer <nng.Operation 'call_main_split_15' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_/s4/b2/f/a_relu/Relu;Add_26;convolution_438;convolution_151;Const_36' shape=[1, 7, 7, 368] dtype=int8> adding consumer <nng.Operation 'transpose_80' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_80' type=Transpose>
<nng.Tensor 'transpose_80' shape=[1, 368, 7, 7] dtype=int8> adding consumer <nng.Operation 'call_main_split_17' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_/s4/b3/f/a_relu/Relu;Add_29;convolution_438;convolution_199;Const_30' shape=[1, 7, 7, 368] dtype=int8> adding consumer <nng.Operation 'transpose_89' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_89' type=Transpose>
<nng.Tensor 'transpose_89' shape=[1, 368, 7, 7] dtype=int8> adding consumer <nng.Operation 'call_main_split_19' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_/s4/b4/f/a_relu/Relu;Add_32;convolution_438;convolution_247;Const_24' shape=[1, 7, 7, 368] dtype=int8> adding consumer <nng.Operation 'transpose_98' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_98' type=Transpose>
<nng.Tensor 'transpose_98' shape=[1, 368, 7, 7] dtype=int8> adding consumer <nng.Operation 'call_main_split_21' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_/s4/b5/f/a_relu/Relu;Add_35;convolution_438;convolution_295;Const_18' shape=[1, 7, 7, 368] dtype=int8> adding consumer <nng.Operation 'transpose_107' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_107' type=Transpose>
<nng.Tensor 'transpose_107' shape=[1, 368, 7, 7] dtype=int8> adding consumer <nng.Operation 'call_main_split_23' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_/s4/b6/f/a_relu/Relu;Add_38;convolution_438;convolution_343;Const_12' shape=[1, 7, 7, 368] dtype=int8> adding consumer <nng.Operation 'transpose_116' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_116' type=Transpose>
<nng.Tensor 'transpose_116' shape=[1, 368, 7, 7] dtype=int8> adding consumer <nng.Operation 'call_main_split_25' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_/s4/b7/f/a_relu/Relu;Add_41;convolution_438;convolution_391;Const_6' shape=[1, 7, 7, 368] dtype=int8> adding consumer <nng.Operation 'transpose_125' type=Transpose>
<nng.Tensor 'transpose_101/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_125' type=Transpose>
<nng.Tensor 'transpose_125' shape=[1, 368, 7, 7] dtype=int8> adding consumer <nng.Operation 'call_main_split_27' type=CustomNpuOp>
<nng.Tensor 'transpose_8_npu' shape=[1, 24, 112, 112] dtype=int8> adding consumer <nng.Operation 'Pad_1_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_1_right_0_npu' shape=[1, 24, 112, 1] dtype=int8> adding consumer <nng.Operation 'Pad_1_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_20_npu' shape=[1, 56, 56, 56] dtype=int8> adding consumer <nng.Operation 'Pad_2_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_2_right_0_npu' shape=[1, 56, 56, 1] dtype=int8> adding consumer <nng.Operation 'Pad_2_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_32_npu' shape=[1, 152, 28, 28] dtype=int8> adding consumer <nng.Operation 'Pad_3_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_3_right_0_npu' shape=[1, 152, 28, 1] dtype=int8> adding consumer <nng.Operation 'Pad_3_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_41_npu' shape=[1, 152, 14, 14] dtype=int8> adding consumer <nng.Operation 'Pad_4_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_4_right_0_npu' shape=[1, 152, 14, 1] dtype=int8> adding consumer <nng.Operation 'Pad_4_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_50_npu' shape=[1, 152, 14, 14] dtype=int8> adding consumer <nng.Operation 'Pad_5_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_5_right_0_npu' shape=[1, 152, 14, 1] dtype=int8> adding consumer <nng.Operation 'Pad_5_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_59_npu' shape=[1, 152, 14, 14] dtype=int8> adding consumer <nng.Operation 'Pad_6_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_6_right_0_npu' shape=[1, 152, 14, 1] dtype=int8> adding consumer <nng.Operation 'Pad_6_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_71_npu' shape=[1, 368, 14, 14] dtype=int8> adding consumer <nng.Operation 'Pad_7_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_7_right_0_npu' shape=[1, 368, 14, 1] dtype=int8> adding consumer <nng.Operation 'Pad_7_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_80_npu' shape=[1, 368, 7, 7] dtype=int8> adding consumer <nng.Operation 'Pad_8_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_8_right_0_npu' shape=[1, 368, 7, 1] dtype=int8> adding consumer <nng.Operation 'Pad_8_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_89_npu' shape=[1, 368, 7, 7] dtype=int8> adding consumer <nng.Operation 'Pad_9_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_9_right_0_npu' shape=[1, 368, 7, 1] dtype=int8> adding consumer <nng.Operation 'Pad_9_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_98_npu' shape=[1, 368, 7, 7] dtype=int8> adding consumer <nng.Operation 'Pad_10_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_10_right_0_npu' shape=[1, 368, 7, 1] dtype=int8> adding consumer <nng.Operation 'Pad_10_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_107_npu' shape=[1, 368, 7, 7] dtype=int8> adding consumer <nng.Operation 'Pad_11_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_11_right_0_npu' shape=[1, 368, 7, 1] dtype=int8> adding consumer <nng.Operation 'Pad_11_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_116_npu' shape=[1, 368, 7, 7] dtype=int8> adding consumer <nng.Operation 'Pad_12_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_12_right_0_npu' shape=[1, 368, 7, 1] dtype=int8> adding consumer <nng.Operation 'Pad_12_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_125_npu' shape=[1, 368, 7, 7] dtype=int8> adding consumer <nng.Operation 'Pad_13_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_13_right_0_npu' shape=[1, 368, 7, 1] dtype=int8> adding consumer <nng.Operation 'Pad_13_concat2_avgpool' type=AvgPool>

Network summary for regnetx200mf_quant
Accelerator configuration               Ethos_U65_256
System configuration                 internal-default
Memory mode                          internal-default
Accelerator clock                                1000 MHz
Design peak SRAM bandwidth                      16.00 GB/s
Design peak DRAM bandwidth                       3.75 GB/s

Total SRAM used                                197.97 KiB
Total DRAM used                               4814.97 KiB

CPU operators = 16 (1.7%)
NPU operators = 920 (98.3%)

Average SRAM bandwidth                           0.39 GB/s
Input   SRAM bandwidth                           3.58 MB/batch
Weight  SRAM bandwidth                          17.12 MB/batch
Output  SRAM bandwidth                           0.00 MB/batch
Total   SRAM bandwidth                          20.81 MB/batch
Total   SRAM bandwidth            per input     20.81 MB/inference (batch size 1)

Average DRAM bandwidth                           0.84 GB/s
Input   DRAM bandwidth                          26.65 MB/batch
Weight  DRAM bandwidth                           2.57 MB/batch
Output  DRAM bandwidth                          15.66 MB/batch
Total   DRAM bandwidth                          44.88 MB/batch
Total   DRAM bandwidth            per input     44.88 MB/inference (batch size 1)

Neural network macs                         804547372 MACs/batch
Network Tops/s                                   0.03 Tops/s

NPU cycles                                   23877460 cycles/batch
SRAM Access cycles                            4696372 cycles/batch
DRAM Access cycles                           42293190 cycles/batch
On-chip Flash Access cycles                         0 cycles/batch
Off-chip Flash Access cycles                        0 cycles/batch
Total cycles                                 53268980 cycles/batch

Batch Inference time                53.27 ms,   18.77 inferences/s (batch size 1)

