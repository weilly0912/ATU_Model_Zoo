Warning: Unsupported TensorFlow Lite semantics for QUANTIZE 'tfl.quantize'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: serving_default_data
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_1'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_2'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for PADV2 'PadV2'. Placing on CPU instead
 - Scalar Input tensors are only valid for op type: ADD, EXPAND_DIMS, MAXIMUM, MEAN, MINIMUM, MUL, QUANTIZE, SPLIT, SPLIT_V, SUB
   Op has scalar input tensor(s): PadV2/constant_values
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_3'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_4'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_6'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_7'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_9'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_10'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_12'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_13'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_15'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_16'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_18'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_19'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_21'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_24'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_25'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_27'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_28'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_30'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_31'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_33'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_34'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_36'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_39'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_40'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_42'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_43'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_45'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_46'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_48'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_49'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_51'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_54'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_55'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_57'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_58'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_60'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_61'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_10/perm
Warning: Unsupported TensorFlow Lite semantics for MEAN 'Mean'. Placing on CPU instead
 - Axis indices must correspond to height and width axes
   Axis is [2, 3]
Warning: Unsupported TensorFlow Lite semantics for DEQUANTIZE 'PartitionedCall'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: PartitionedCall
Warning: Mean operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: PadV2 operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Quantize operation is unknown or unsupported, placing on CPU
<nng.Tensor 'MaxPool2d' shape=[1, 56, 56, 64] dtype=int8> adding consumer <nng.Operation 'transpose_4' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_4' type=Transpose>
<nng.Tensor 'transpose_4' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'call_main_split_5' type=CustomNpuOp>
<nng.Tensor 'Pad_1' shape=[1, 64, 58, 58] dtype=int8> adding consumer <nng.Operation 'transpose_6' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_6' type=Transpose>
<nng.Tensor 'transpose_6' shape=[1, 58, 58, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_6' type=CustomNpuOp>
<nng.Tensor 'convolution_110' shape=[1, 56, 56, 64] dtype=int8> adding consumer <nng.Operation 'transpose_7' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_7' type=Transpose>
<nng.Tensor 'transpose_7' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'call_main_split_7' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1__plus0' shape=[1, 56, 56, 64] dtype=int8> adding consumer <nng.Operation 'transpose_10' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_10' type=Transpose>
<nng.Tensor 'transpose_10' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'call_main_split_9' type=CustomNpuOp>
<nng.Tensor 'Pad_3' shape=[1, 64, 58, 58] dtype=int8> adding consumer <nng.Operation 'transpose_12' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_12' type=Transpose>
<nng.Tensor 'transpose_12' shape=[1, 58, 58, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_10' type=CustomNpuOp>
<nng.Tensor 'convolution_31' shape=[1, 56, 56, 64] dtype=int8> adding consumer <nng.Operation 'transpose_13' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_13' type=Transpose>
<nng.Tensor 'transpose_13' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'call_main_split_11' type=CustomNpuOp>
<nng.Tensor 'Pad_5' shape=[1, 64, 58, 58] dtype=int8> adding consumer <nng.Operation 'transpose_18' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_18' type=Transpose>
<nng.Tensor 'transpose_18' shape=[1, 58, 58, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_15' type=CustomNpuOp>
<nng.Tensor 'convolution_51' shape=[1, 28, 28, 128] dtype=int8> adding consumer <nng.Operation 'transpose_19' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_19' type=Transpose>
<nng.Tensor 'transpose_19' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'call_main_split_16' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2__plus0' shape=[1, 28, 28, 128] dtype=int8> adding consumer <nng.Operation 'transpose_25' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_25' type=Transpose>
<nng.Tensor 'transpose_25' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'call_main_split_18' type=CustomNpuOp>
<nng.Tensor 'Pad_7' shape=[1, 128, 30, 30] dtype=int8> adding consumer <nng.Operation 'transpose_27' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_27' type=Transpose>
<nng.Tensor 'transpose_27' shape=[1, 30, 30, 128] dtype=int8> adding consumer <nng.Operation 'call_main_split_19' type=CustomNpuOp>
<nng.Tensor 'convolution_81' shape=[1, 28, 28, 128] dtype=int8> adding consumer <nng.Operation 'transpose_28' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_28' type=Transpose>
<nng.Tensor 'transpose_28' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'call_main_split_20' type=CustomNpuOp>
<nng.Tensor 'Pad_9' shape=[1, 128, 30, 30] dtype=int8> adding consumer <nng.Operation 'transpose_33' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_33' type=Transpose>
<nng.Tensor 'transpose_33' shape=[1, 30, 30, 128] dtype=int8> adding consumer <nng.Operation 'call_main_split_24' type=CustomNpuOp>
<nng.Tensor 'convolution_101' shape=[1, 14, 14, 256] dtype=int8> adding consumer <nng.Operation 'transpose_34' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_34' type=Transpose>
<nng.Tensor 'transpose_34' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'call_main_split_25' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3__plus0' shape=[1, 14, 14, 256] dtype=int8> adding consumer <nng.Operation 'transpose_40' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_40' type=Transpose>
<nng.Tensor 'transpose_40' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'call_main_split_27' type=CustomNpuOp>
<nng.Tensor 'Pad_11' shape=[1, 256, 16, 16] dtype=int8> adding consumer <nng.Operation 'transpose_42' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_42' type=Transpose>
<nng.Tensor 'transpose_42' shape=[1, 16, 16, 256] dtype=int8> adding consumer <nng.Operation 'call_main_split_28' type=CustomNpuOp>
<nng.Tensor 'convolution_131' shape=[1, 14, 14, 256] dtype=int8> adding consumer <nng.Operation 'transpose_43' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_43' type=Transpose>
<nng.Tensor 'transpose_43' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'call_main_split_29' type=CustomNpuOp>
<nng.Tensor 'Pad_13' shape=[1, 256, 16, 16] dtype=int8> adding consumer <nng.Operation 'transpose_48' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_48' type=Transpose>
<nng.Tensor 'transpose_48' shape=[1, 16, 16, 256] dtype=int8> adding consumer <nng.Operation 'call_main_split_33' type=CustomNpuOp>
<nng.Tensor 'convolution_151' shape=[1, 7, 7, 512] dtype=int8> adding consumer <nng.Operation 'transpose_49' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_49' type=Transpose>
<nng.Tensor 'transpose_49' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'call_main_split_34' type=CustomNpuOp>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4__plus0' shape=[1, 7, 7, 512] dtype=int8> adding consumer <nng.Operation 'transpose_55' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_55' type=Transpose>
<nng.Tensor 'transpose_55' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'call_main_split_36' type=CustomNpuOp>
<nng.Tensor 'Pad_15' shape=[1, 512, 9, 9] dtype=int8> adding consumer <nng.Operation 'transpose_57' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_57' type=Transpose>
<nng.Tensor 'transpose_57' shape=[1, 9, 9, 512] dtype=int8> adding consumer <nng.Operation 'call_main_split_37' type=CustomNpuOp>
<nng.Tensor 'convolution_181' shape=[1, 7, 7, 512] dtype=int8> adding consumer <nng.Operation 'transpose_58' type=Transpose>
<nng.Tensor 'transpose_10/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_58' type=Transpose>
<nng.Tensor 'transpose_58' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'call_main_split_38' type=CustomNpuOp>
<nng.Tensor 'transpose_4_npu' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_batchnorm0_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_batchnorm0_fwd/mul_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_batchnorm0_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_batchnorm0_fwd/mul_1' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_activation0;onnx_tf_prefix_resnetv22_stage1_batchnorm0_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_batchnorm0_fwd/sub_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_activation0;onnx_tf_prefix_resnetv22_stage1_batchnorm0_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_activation0;onnx_tf_prefix_resnetv22_stage1_batchnorm0_fwd/add_1' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'Pad_1_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_1_right_0_npu' shape=[1, 64, 56, 1] dtype=int8> adding consumer <nng.Operation 'Pad_1_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_7_npu' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_batchnorm1_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_batchnorm1_fwd/mul_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_batchnorm1_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_batchnorm1_fwd/mul_1' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_activation1;onnx_tf_prefix_resnetv22_stage1_batchnorm1_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_batchnorm1_fwd/sub_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_activation1;onnx_tf_prefix_resnetv22_stage1_batchnorm1_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_activation1;onnx_tf_prefix_resnetv22_stage1_batchnorm1_fwd/add_1' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'Pad_2_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_2_right_0_npu' shape=[1, 64, 56, 1] dtype=int8> adding consumer <nng.Operation 'Pad_2_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_10_npu' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_batchnorm2_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_batchnorm2_fwd/mul_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_batchnorm2_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_batchnorm2_fwd/mul_1' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_activation2;onnx_tf_prefix_resnetv22_stage1_batchnorm2_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_batchnorm2_fwd/sub_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_activation2;onnx_tf_prefix_resnetv22_stage1_batchnorm2_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_activation2;onnx_tf_prefix_resnetv22_stage1_batchnorm2_fwd/add_1' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'Pad_3_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_3_right_0_npu' shape=[1, 64, 56, 1] dtype=int8> adding consumer <nng.Operation 'Pad_3_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_13_npu' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_batchnorm3_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_batchnorm3_fwd/mul_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_batchnorm3_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_batchnorm3_fwd/mul_1' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_activation3;onnx_tf_prefix_resnetv22_stage1_batchnorm3_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_batchnorm3_fwd/sub_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage1_activation3;onnx_tf_prefix_resnetv22_stage1_batchnorm3_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage1_activation3;onnx_tf_prefix_resnetv22_stage1_batchnorm3_fwd/add_1' shape=[1, 64, 56, 56] dtype=int8> adding consumer <nng.Operation 'Pad_4_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_4_right_0_npu' shape=[1, 64, 56, 1] dtype=int8> adding consumer <nng.Operation 'Pad_4_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_19_npu' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage2_batchnorm1_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2_batchnorm1_fwd/mul_npu' shape=[1, 128, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage2_batchnorm1_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2_batchnorm1_fwd/mul_1' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage2_activation1;onnx_tf_prefix_resnetv22_stage2_batchnorm1_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2_batchnorm1_fwd/sub_npu' shape=[1, 128, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage2_activation1;onnx_tf_prefix_resnetv22_stage2_batchnorm1_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2_activation1;onnx_tf_prefix_resnetv22_stage2_batchnorm1_fwd/add_1' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'Pad_6_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_6_right_0_npu' shape=[1, 128, 28, 1] dtype=int8> adding consumer <nng.Operation 'Pad_6_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_25_npu' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage2_batchnorm2_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2_batchnorm2_fwd/mul_npu' shape=[1, 128, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage2_batchnorm2_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2_batchnorm2_fwd/mul_1' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage2_activation2;onnx_tf_prefix_resnetv22_stage2_batchnorm2_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2_batchnorm2_fwd/sub_npu' shape=[1, 128, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage2_activation2;onnx_tf_prefix_resnetv22_stage2_batchnorm2_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2_activation2;onnx_tf_prefix_resnetv22_stage2_batchnorm2_fwd/add_1' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'Pad_7_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_7_right_0_npu' shape=[1, 128, 28, 1] dtype=int8> adding consumer <nng.Operation 'Pad_7_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_28_npu' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage2_batchnorm3_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2_batchnorm3_fwd/mul_npu' shape=[1, 128, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage2_batchnorm3_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2_batchnorm3_fwd/mul_1' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage2_activation3;onnx_tf_prefix_resnetv22_stage2_batchnorm3_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2_batchnorm3_fwd/sub_npu' shape=[1, 128, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage2_activation3;onnx_tf_prefix_resnetv22_stage2_batchnorm3_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage2_activation3;onnx_tf_prefix_resnetv22_stage2_batchnorm3_fwd/add_1' shape=[1, 128, 28, 28] dtype=int8> adding consumer <nng.Operation 'Pad_8_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_8_right_0_npu' shape=[1, 128, 28, 1] dtype=int8> adding consumer <nng.Operation 'Pad_8_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_34_npu' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage3_batchnorm1_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3_batchnorm1_fwd/mul_npu' shape=[1, 256, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage3_batchnorm1_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3_batchnorm1_fwd/mul_1' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage3_activation1;onnx_tf_prefix_resnetv22_stage3_batchnorm1_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3_batchnorm1_fwd/sub_npu' shape=[1, 256, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage3_activation1;onnx_tf_prefix_resnetv22_stage3_batchnorm1_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3_activation1;onnx_tf_prefix_resnetv22_stage3_batchnorm1_fwd/add_1' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'Pad_10_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_10_right_0_npu' shape=[1, 256, 14, 1] dtype=int8> adding consumer <nng.Operation 'Pad_10_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_40_npu' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage3_batchnorm2_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3_batchnorm2_fwd/mul_npu' shape=[1, 256, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage3_batchnorm2_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3_batchnorm2_fwd/mul_1' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage3_activation2;onnx_tf_prefix_resnetv22_stage3_batchnorm2_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3_batchnorm2_fwd/sub_npu' shape=[1, 256, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage3_activation2;onnx_tf_prefix_resnetv22_stage3_batchnorm2_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3_activation2;onnx_tf_prefix_resnetv22_stage3_batchnorm2_fwd/add_1' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'Pad_11_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_11_right_0_npu' shape=[1, 256, 14, 1] dtype=int8> adding consumer <nng.Operation 'Pad_11_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_43_npu' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage3_batchnorm3_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3_batchnorm3_fwd/mul_npu' shape=[1, 256, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage3_batchnorm3_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3_batchnorm3_fwd/mul_1' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage3_activation3;onnx_tf_prefix_resnetv22_stage3_batchnorm3_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3_batchnorm3_fwd/sub_npu' shape=[1, 256, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage3_activation3;onnx_tf_prefix_resnetv22_stage3_batchnorm3_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage3_activation3;onnx_tf_prefix_resnetv22_stage3_batchnorm3_fwd/add_1' shape=[1, 256, 14, 14] dtype=int8> adding consumer <nng.Operation 'Pad_12_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_12_right_0_npu' shape=[1, 256, 14, 1] dtype=int8> adding consumer <nng.Operation 'Pad_12_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_49_npu' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage4_batchnorm1_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4_batchnorm1_fwd/mul_npu' shape=[1, 512, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage4_batchnorm1_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4_batchnorm1_fwd/mul_1' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage4_activation1;onnx_tf_prefix_resnetv22_stage4_batchnorm1_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4_batchnorm1_fwd/sub_npu' shape=[1, 512, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage4_activation1;onnx_tf_prefix_resnetv22_stage4_batchnorm1_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4_activation1;onnx_tf_prefix_resnetv22_stage4_batchnorm1_fwd/add_1' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'Pad_14_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_14_right_0_npu' shape=[1, 512, 7, 1] dtype=int8> adding consumer <nng.Operation 'Pad_14_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_55_npu' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage4_batchnorm2_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4_batchnorm2_fwd/mul_npu' shape=[1, 512, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage4_batchnorm2_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4_batchnorm2_fwd/mul_1' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage4_activation2;onnx_tf_prefix_resnetv22_stage4_batchnorm2_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4_batchnorm2_fwd/sub_npu' shape=[1, 512, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage4_activation2;onnx_tf_prefix_resnetv22_stage4_batchnorm2_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4_activation2;onnx_tf_prefix_resnetv22_stage4_batchnorm2_fwd/add_1' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'Pad_15_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_15_right_0_npu' shape=[1, 512, 7, 1] dtype=int8> adding consumer <nng.Operation 'Pad_15_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_58_npu' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage4_batchnorm3_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4_batchnorm3_fwd/mul_npu' shape=[1, 512, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage4_batchnorm3_fwd/mul_1' type=Mul>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4_batchnorm3_fwd/mul_1' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage4_activation3;onnx_tf_prefix_resnetv22_stage4_batchnorm3_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4_batchnorm3_fwd/sub_npu' shape=[1, 512, 1, 1] dtype=int8> adding consumer <nng.Operation 'onnx_tf_prefix_resnetv22_stage4_activation3;onnx_tf_prefix_resnetv22_stage4_batchnorm3_fwd/add_1' type=Add>
<nng.Tensor 'onnx_tf_prefix_resnetv22_stage4_activation3;onnx_tf_prefix_resnetv22_stage4_batchnorm3_fwd/add_1' shape=[1, 512, 7, 7] dtype=int8> adding consumer <nng.Operation 'Pad_16_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_16_right_0_npu' shape=[1, 512, 7, 1] dtype=int8> adding consumer <nng.Operation 'Pad_16_concat2_avgpool' type=AvgPool>

Network summary for resnet_v2_18_quant
Accelerator configuration               Ethos_U65_256
System configuration                 internal-default
Memory mode                          internal-default
Accelerator clock                                1000 MHz
Design peak SRAM bandwidth                      16.00 GB/s
Design peak DRAM bandwidth                       3.75 GB/s

Total SRAM used                                383.92 KiB
Total DRAM used                              11909.88 KiB

CPU operators = 22 (15.6%)
NPU operators = 119 (84.4%)

Average SRAM bandwidth                           0.68 GB/s
Input   SRAM bandwidth                           6.14 MB/batch
Weight  SRAM bandwidth                          35.83 MB/batch
Output  SRAM bandwidth                           0.00 MB/batch
Total   SRAM bandwidth                          42.02 MB/batch
Total   SRAM bandwidth            per input     42.02 MB/inference (batch size 1)

Average DRAM bandwidth                           0.79 GB/s
Input   DRAM bandwidth                          23.02 MB/batch
Weight  DRAM bandwidth                          10.31 MB/batch
Output  DRAM bandwidth                          15.64 MB/batch
Total   DRAM bandwidth                          48.98 MB/batch
Total   DRAM bandwidth            per input     48.98 MB/inference (batch size 1)

Neural network macs                        1822127300 MACs/batch
Network Tops/s                                   0.06 Tops/s

NPU cycles                                   25208749 cycles/batch
SRAM Access cycles                             770856 cycles/batch
DRAM Access cycles                           60930181 cycles/batch
On-chip Flash Access cycles                         0 cycles/batch
Off-chip Flash Access cycles                        0 cycles/batch
Total cycles                                 61889917 cycles/batch

Batch Inference time                61.89 ms,   16.16 inferences/s (batch size 1)

