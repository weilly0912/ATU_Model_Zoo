Warning: Unsupported TensorFlow Lite semantics for QUANTIZE 'tfl.quantize'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: serving_default_input:0
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_1'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_2'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_4'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_5'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'batchnorm_1/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_8'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_10'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'batchnorm_3/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_14'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_16'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_17'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'batchnorm_5/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_20'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_22'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_23'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'batchnorm_7/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_26'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_28'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_29'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'batchnorm_9/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_32'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_34'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_35'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'batchnorm_11/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_38'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_40'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_41'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'batchnorm_13/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_44'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_60'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_61'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'batchnorm_15/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_64'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_66'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_67'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'batchnorm_17/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_70'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_72'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_73'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'batchnorm_19/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_76'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_78'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_93'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'batchnorm_21/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_96'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_98'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_99'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'batchnorm_23/add_11'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_102'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_104'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_118'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_119'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_121'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_125'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_102/perm
Warning: Unsupported TensorFlow Lite semantics for TRANSPOSE 'transpose_127'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: transpose_1/perm
Warning: Unsupported TensorFlow Lite semantics for DEQUANTIZE 'tfl.dequantize'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: tfl.dequantize
Warning: Unsupported TensorFlow Lite semantics for EXP 'Exp'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: tfl.dequantize, Exp
Warning: Unsupported TensorFlow Lite semantics for QUANTIZE 'tfl.quantize1'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: Exp
Warning: Unsupported TensorFlow Lite semantics for DEQUANTIZE 'PartitionedCall:0'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: PartitionedCall:0
Warning: Unsupported TensorFlow Lite semantics for DEQUANTIZE 'PartitionedCall:1'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: PartitionedCall:1
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Transpose operation is unknown or unsupported, placing on CPU
Warning: Quantize operation is unknown or unsupported, placing on CPU
<nng.Tensor 'Pad' shape=[1, 3, 242, 322] dtype=int8> adding consumer <nng.Operation 'transpose_1' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_1' type=Transpose>
<nng.Tensor 'transpose_1' shape=[1, 242, 322, 3] dtype=int8> adding consumer <nng.Operation 'call_main_split_2' type=CustomNpuOp>
<nng.Tensor 'convolution1' shape=[1, 120, 160, 16] dtype=int8> adding consumer <nng.Operation 'transpose_2' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_2' type=Transpose>
<nng.Tensor 'transpose_2' shape=[1, 16, 120, 160] dtype=int8> adding consumer <nng.Operation 'call_main_split_3' type=CustomNpuOp>
<nng.Tensor 'Pad_1' shape=[1, 16, 122, 162] dtype=int8> adding consumer <nng.Operation 'transpose_4' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_4' type=Transpose>
<nng.Tensor 'transpose_4' shape=[1, 122, 162, 16] dtype=int8> adding consumer <nng.Operation 'call_main_split_4' type=CustomNpuOp>
<nng.Tensor 'depthwise21' shape=[1, 120, 160, 16] dtype=int8> adding consumer <nng.Operation 'transpose_5' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_5' type=Transpose>
<nng.Tensor 'transpose_5' shape=[1, 16, 120, 160] dtype=int8> adding consumer <nng.Operation 'call_main_split_5' type=CustomNpuOp>
<nng.Tensor 'batchnorm_1/mul_1' shape=[1, 16, 120, 160] dtype=int8> adding consumer <nng.Operation 'batchnorm_1/add_11' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'batchnorm_1/add_11' type=Transpose>
<nng.Tensor 'batchnorm_1/add_11' shape=[1, 120, 160, 16] dtype=int8> adding consumer <nng.Operation 'call_main_split_6' type=CustomNpuOp>
<nng.Tensor 'convolution_110' shape=[1, 120, 160, 32] dtype=int8> adding consumer <nng.Operation 'transpose_8' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_8' type=Transpose>
<nng.Tensor 'transpose_8' shape=[1, 32, 120, 160] dtype=int8> adding consumer <nng.Operation 'call_main_split_7' type=CustomNpuOp>
<nng.Tensor 'Pad_2' shape=[1, 32, 122, 162] dtype=int8> adding consumer <nng.Operation 'transpose_10' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_10' type=Transpose>
<nng.Tensor 'transpose_10' shape=[1, 122, 162, 32] dtype=int8> adding consumer <nng.Operation 'call_main_split_8' type=CustomNpuOp>
<nng.Tensor 'depthwise_19' shape=[1, 60, 80, 32] dtype=int8> adding consumer <nng.Operation 'transpose_11' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_11' type=Transpose>
<nng.Tensor 'transpose_11' shape=[1, 32, 60, 80] dtype=int8> adding consumer <nng.Operation 'call_main_split_9' type=CustomNpuOp>
<nng.Tensor 'batchnorm_3/mul_1' shape=[1, 32, 60, 80] dtype=int8> adding consumer <nng.Operation 'batchnorm_3/add_11' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'batchnorm_3/add_11' type=Transpose>
<nng.Tensor 'batchnorm_3/add_11' shape=[1, 60, 80, 32] dtype=int8> adding consumer <nng.Operation 'call_main_split_10' type=CustomNpuOp>
<nng.Tensor 'convolution_23' shape=[1, 60, 80, 32] dtype=int8> adding consumer <nng.Operation 'transpose_14' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_14' type=Transpose>
<nng.Tensor 'transpose_14' shape=[1, 32, 60, 80] dtype=int8> adding consumer <nng.Operation 'call_main_split_11' type=CustomNpuOp>
<nng.Tensor 'Pad_3' shape=[1, 32, 62, 82] dtype=int8> adding consumer <nng.Operation 'transpose_16' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_16' type=Transpose>
<nng.Tensor 'transpose_16' shape=[1, 62, 82, 32] dtype=int8> adding consumer <nng.Operation 'call_main_split_12' type=CustomNpuOp>
<nng.Tensor 'depthwise_21' shape=[1, 60, 80, 32] dtype=int8> adding consumer <nng.Operation 'transpose_17' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_17' type=Transpose>
<nng.Tensor 'transpose_17' shape=[1, 32, 60, 80] dtype=int8> adding consumer <nng.Operation 'call_main_split_13' type=CustomNpuOp>
<nng.Tensor 'batchnorm_5/mul_1' shape=[1, 32, 60, 80] dtype=int8> adding consumer <nng.Operation 'batchnorm_5/add_11' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'batchnorm_5/add_11' type=Transpose>
<nng.Tensor 'batchnorm_5/add_11' shape=[1, 60, 80, 32] dtype=int8> adding consumer <nng.Operation 'call_main_split_14' type=CustomNpuOp>
<nng.Tensor 'convolution_31' shape=[1, 60, 80, 32] dtype=int8> adding consumer <nng.Operation 'transpose_20' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_20' type=Transpose>
<nng.Tensor 'transpose_20' shape=[1, 32, 60, 80] dtype=int8> adding consumer <nng.Operation 'call_main_split_15' type=CustomNpuOp>
<nng.Tensor 'Pad_4' shape=[1, 32, 62, 82] dtype=int8> adding consumer <nng.Operation 'transpose_22' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_22' type=Transpose>
<nng.Tensor 'transpose_22' shape=[1, 62, 82, 32] dtype=int8> adding consumer <nng.Operation 'call_main_split_16' type=CustomNpuOp>
<nng.Tensor 'depthwise_321' shape=[1, 30, 40, 32] dtype=int8> adding consumer <nng.Operation 'transpose_23' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_23' type=Transpose>
<nng.Tensor 'transpose_23' shape=[1, 32, 30, 40] dtype=int8> adding consumer <nng.Operation 'call_main_split_17' type=CustomNpuOp>
<nng.Tensor 'batchnorm_7/mul_1' shape=[1, 32, 30, 40] dtype=int8> adding consumer <nng.Operation 'batchnorm_7/add_11' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'batchnorm_7/add_11' type=Transpose>
<nng.Tensor 'batchnorm_7/add_11' shape=[1, 30, 40, 32] dtype=int8> adding consumer <nng.Operation 'call_main_split_18' type=CustomNpuOp>
<nng.Tensor 'convolution_41' shape=[1, 30, 40, 64] dtype=int8> adding consumer <nng.Operation 'transpose_26' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_26' type=Transpose>
<nng.Tensor 'transpose_26' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'call_main_split_19' type=CustomNpuOp>
<nng.Tensor 'Pad_5' shape=[1, 64, 32, 42] dtype=int8> adding consumer <nng.Operation 'transpose_28' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_28' type=Transpose>
<nng.Tensor 'transpose_28' shape=[1, 32, 42, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_20' type=CustomNpuOp>
<nng.Tensor 'depthwise_41' shape=[1, 30, 40, 64] dtype=int8> adding consumer <nng.Operation 'transpose_29' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_29' type=Transpose>
<nng.Tensor 'transpose_29' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'call_main_split_21' type=CustomNpuOp>
<nng.Tensor 'batchnorm_9/mul_1' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'batchnorm_9/add_11' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'batchnorm_9/add_11' type=Transpose>
<nng.Tensor 'batchnorm_9/add_11' shape=[1, 30, 40, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_22' type=CustomNpuOp>
<nng.Tensor 'convolution_51' shape=[1, 30, 40, 64] dtype=int8> adding consumer <nng.Operation 'transpose_32' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_32' type=Transpose>
<nng.Tensor 'transpose_32' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'call_main_split_23' type=CustomNpuOp>
<nng.Tensor 'Pad_6' shape=[1, 64, 32, 42] dtype=int8> adding consumer <nng.Operation 'transpose_34' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_34' type=Transpose>
<nng.Tensor 'transpose_34' shape=[1, 32, 42, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_24' type=CustomNpuOp>
<nng.Tensor 'depthwise_51' shape=[1, 30, 40, 64] dtype=int8> adding consumer <nng.Operation 'transpose_35' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_35' type=Transpose>
<nng.Tensor 'transpose_35' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'call_main_split_25' type=CustomNpuOp>
<nng.Tensor 'batchnorm_11/mul_1' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'batchnorm_11/add_11' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'batchnorm_11/add_11' type=Transpose>
<nng.Tensor 'batchnorm_11/add_11' shape=[1, 30, 40, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_26' type=CustomNpuOp>
<nng.Tensor 'convolution_61' shape=[1, 30, 40, 64] dtype=int8> adding consumer <nng.Operation 'transpose_38' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_38' type=Transpose>
<nng.Tensor 'transpose_38' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'call_main_split_27' type=CustomNpuOp>
<nng.Tensor 'Pad_7' shape=[1, 64, 32, 42] dtype=int8> adding consumer <nng.Operation 'transpose_40' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_40' type=Transpose>
<nng.Tensor 'transpose_40' shape=[1, 32, 42, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_28' type=CustomNpuOp>
<nng.Tensor 'depthwise_61' shape=[1, 30, 40, 64] dtype=int8> adding consumer <nng.Operation 'transpose_41' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_41' type=Transpose>
<nng.Tensor 'transpose_41' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'call_main_split_29' type=CustomNpuOp>
<nng.Tensor 'batchnorm_13/mul_1' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'batchnorm_13/add_11' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'batchnorm_13/add_11' type=Transpose>
<nng.Tensor 'batchnorm_13/add_11' shape=[1, 30, 40, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_30' type=CustomNpuOp>
<nng.Tensor 'convolution_71' shape=[1, 30, 40, 64] dtype=int8> adding consumer <nng.Operation 'transpose_44' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_44' type=Transpose>
<nng.Tensor 'transpose_44' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'call_main_split_31' type=CustomNpuOp>
<nng.Tensor 'depthwise_91' shape=[1, 15, 20, 64] dtype=int8> adding consumer <nng.Operation 'transpose_61' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_61' type=Transpose>
<nng.Tensor 'transpose_61' shape=[1, 64, 15, 20] dtype=int8> adding consumer <nng.Operation 'call_main_split_33' type=CustomNpuOp>
<nng.Tensor 'batchnorm_15/mul_1' shape=[1, 64, 15, 20] dtype=int8> adding consumer <nng.Operation 'batchnorm_15/add_11' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'batchnorm_15/add_11' type=Transpose>
<nng.Tensor 'batchnorm_15/add_11' shape=[1, 15, 20, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_34' type=CustomNpuOp>
<nng.Tensor 'convolution_101' shape=[1, 15, 20, 128] dtype=int8> adding consumer <nng.Operation 'transpose_64' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_64' type=Transpose>
<nng.Tensor 'transpose_64' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'call_main_split_35' type=CustomNpuOp>
<nng.Tensor 'Pad_11' shape=[1, 128, 17, 22] dtype=int8> adding consumer <nng.Operation 'transpose_66' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_66' type=Transpose>
<nng.Tensor 'transpose_66' shape=[1, 17, 22, 128] dtype=int8> adding consumer <nng.Operation 'call_main_split_36' type=CustomNpuOp>
<nng.Tensor 'depthwise_101' shape=[1, 15, 20, 128] dtype=int8> adding consumer <nng.Operation 'transpose_67' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_67' type=Transpose>
<nng.Tensor 'transpose_67' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'call_main_split_37' type=CustomNpuOp>
<nng.Tensor 'batchnorm_17/mul_1' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'batchnorm_17/add_11' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'batchnorm_17/add_11' type=Transpose>
<nng.Tensor 'batchnorm_17/add_11' shape=[1, 15, 20, 128] dtype=int8> adding consumer <nng.Operation 'call_main_split_38' type=CustomNpuOp>
<nng.Tensor 'convolution_111' shape=[1, 15, 20, 128] dtype=int8> adding consumer <nng.Operation 'transpose_70' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_70' type=Transpose>
<nng.Tensor 'transpose_70' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'call_main_split_39' type=CustomNpuOp>
<nng.Tensor 'Pad_12' shape=[1, 128, 17, 22] dtype=int8> adding consumer <nng.Operation 'transpose_72' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_72' type=Transpose>
<nng.Tensor 'transpose_72' shape=[1, 17, 22, 128] dtype=int8> adding consumer <nng.Operation 'call_main_split_40' type=CustomNpuOp>
<nng.Tensor 'depthwise_111' shape=[1, 15, 20, 128] dtype=int8> adding consumer <nng.Operation 'transpose_73' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_73' type=Transpose>
<nng.Tensor 'transpose_73' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'call_main_split_41' type=CustomNpuOp>
<nng.Tensor 'batchnorm_19/mul_1' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'batchnorm_19/add_11' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'batchnorm_19/add_11' type=Transpose>
<nng.Tensor 'batchnorm_19/add_11' shape=[1, 15, 20, 128] dtype=int8> adding consumer <nng.Operation 'call_main_split_42' type=CustomNpuOp>
<nng.Tensor 'convolution_121' shape=[1, 15, 20, 128] dtype=int8> adding consumer <nng.Operation 'transpose_76' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_76' type=Transpose>
<nng.Tensor 'transpose_76' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'call_main_split_43' type=CustomNpuOp>
<nng.Tensor 'depthwise_1421' shape=[1, 8, 10, 128] dtype=int8> adding consumer <nng.Operation 'transpose_93' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_93' type=Transpose>
<nng.Tensor 'transpose_93' shape=[1, 128, 8, 10] dtype=int8> adding consumer <nng.Operation 'call_main_split_45' type=CustomNpuOp>
<nng.Tensor 'batchnorm_21/mul_1' shape=[1, 128, 8, 10] dtype=int8> adding consumer <nng.Operation 'batchnorm_21/add_11' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'batchnorm_21/add_11' type=Transpose>
<nng.Tensor 'batchnorm_21/add_11' shape=[1, 8, 10, 128] dtype=int8> adding consumer <nng.Operation 'call_main_split_46' type=CustomNpuOp>
<nng.Tensor 'convolution_151' shape=[1, 8, 10, 256] dtype=int8> adding consumer <nng.Operation 'transpose_96' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_96' type=Transpose>
<nng.Tensor 'transpose_96' shape=[1, 256, 8, 10] dtype=int8> adding consumer <nng.Operation 'call_main_split_47' type=CustomNpuOp>
<nng.Tensor 'Pad_16' shape=[1, 256, 10, 12] dtype=int8> adding consumer <nng.Operation 'transpose_98' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_98' type=Transpose>
<nng.Tensor 'transpose_98' shape=[1, 10, 12, 256] dtype=int8> adding consumer <nng.Operation 'call_main_split_48' type=CustomNpuOp>
<nng.Tensor 'depthwise_151' shape=[1, 8, 10, 256] dtype=int8> adding consumer <nng.Operation 'transpose_99' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_99' type=Transpose>
<nng.Tensor 'transpose_99' shape=[1, 256, 8, 10] dtype=int8> adding consumer <nng.Operation 'call_main_split_49' type=CustomNpuOp>
<nng.Tensor 'batchnorm_23/mul_1' shape=[1, 256, 8, 10] dtype=int8> adding consumer <nng.Operation 'batchnorm_23/add_11' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'batchnorm_23/add_11' type=Transpose>
<nng.Tensor 'batchnorm_23/add_11' shape=[1, 8, 10, 256] dtype=int8> adding consumer <nng.Operation 'call_main_split_50' type=CustomNpuOp>
<nng.Tensor 'convolution_161' shape=[1, 8, 10, 256] dtype=int8> adding consumer <nng.Operation 'transpose_102' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_102' type=Transpose>
<nng.Tensor 'transpose_102' shape=[1, 256, 8, 10] dtype=int8> adding consumer <nng.Operation 'call_main_split_51' type=CustomNpuOp>
<nng.Tensor 'Relu_28;batchnorm_24/add_1' shape=[1, 256, 8, 10] dtype=int8> adding consumer <nng.Operation 'transpose_118' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_118' type=Transpose>
<nng.Tensor 'transpose_118' shape=[1, 8, 10, 256] dtype=int8> adding consumer <nng.Operation 'call_main_split_53' type=CustomNpuOp>
<nng.Tensor 'Relu_31;Add_18;depthwise_8;convolution_19;Const_8' shape=[1, 8, 10, 64] dtype=int8> adding consumer <nng.Operation 'transpose_119' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_119' type=Transpose>
<nng.Tensor 'transpose_119' shape=[1, 64, 8, 10] dtype=int8> adding consumer <nng.Operation 'call_main_split_54' type=CustomNpuOp>
<nng.Tensor 'Pad_19' shape=[1, 64, 10, 12] dtype=int8> adding consumer <nng.Operation 'transpose_121' type=Transpose>
<nng.Tensor 'transpose_1/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_121' type=Transpose>
<nng.Tensor 'transpose_121' shape=[1, 10, 12, 64] dtype=int8> adding consumer <nng.Operation 'call_main_split_55' type=CustomNpuOp>
<nng.Tensor 'Relu_33;Add_20;convolution_20;Const_4' shape=[1, 4, 5, 256] dtype=int8> adding consumer <nng.Operation 'transpose_125' type=Transpose>
<nng.Tensor 'transpose_102/perm' shape=[4] dtype=int32> adding consumer <nng.Operation 'transpose_125' type=Transpose>
<nng.Tensor 'transpose_125' shape=[1, 256, 4, 5] dtype=int8> adding consumer <nng.Operation 'call_main_split_56' type=CustomNpuOp>
<nng.Tensor 'transpose_2_npu' shape=[1, 16, 120, 160] dtype=int8> adding consumer <nng.Operation 'batchnorm/mul_1' type=Mul>
<nng.Tensor 'batchnorm/mul_npu' shape=[1, 16, 1, 1] dtype=int8> adding consumer <nng.Operation 'batchnorm/mul_1' type=Mul>
<nng.Tensor 'batchnorm/mul_1' shape=[1, 16, 120, 160] dtype=int8> adding consumer <nng.Operation 'Relu;batchnorm/add_1' type=Add>
<nng.Tensor 'batchnorm/sub_npu' shape=[1, 16, 1, 1] dtype=int8> adding consumer <nng.Operation 'Relu;batchnorm/add_1' type=Add>
<nng.Tensor 'Relu;batchnorm/add_1' shape=[1, 16, 120, 160] dtype=int8> adding consumer <nng.Operation 'Pad_1_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_1_right_0_npu' shape=[1, 16, 120, 1] dtype=int8> adding consumer <nng.Operation 'Pad_1_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_8_npu' shape=[1, 32, 120, 160] dtype=int8> adding consumer <nng.Operation 'batchnorm_2/mul_1' type=Mul>
<nng.Tensor 'batchnorm_2/mul_npu' shape=[1, 32, 1, 1] dtype=int8> adding consumer <nng.Operation 'batchnorm_2/mul_1' type=Mul>
<nng.Tensor 'batchnorm_2/mul_1' shape=[1, 32, 120, 160] dtype=int8> adding consumer <nng.Operation 'Relu_2;batchnorm_2/add_1' type=Add>
<nng.Tensor 'batchnorm_2/sub_npu' shape=[1, 32, 1, 1] dtype=int8> adding consumer <nng.Operation 'Relu_2;batchnorm_2/add_1' type=Add>
<nng.Tensor 'Relu_2;batchnorm_2/add_1' shape=[1, 32, 120, 160] dtype=int8> adding consumer <nng.Operation 'Pad_2_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_2_right_0_npu' shape=[1, 32, 120, 1] dtype=int8> adding consumer <nng.Operation 'Pad_2_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_14_npu' shape=[1, 32, 60, 80] dtype=int8> adding consumer <nng.Operation 'batchnorm_4/mul_1' type=Mul>
<nng.Tensor 'batchnorm_4/mul_npu' shape=[1, 32, 1, 1] dtype=int8> adding consumer <nng.Operation 'batchnorm_4/mul_1' type=Mul>
<nng.Tensor 'batchnorm_4/mul_1' shape=[1, 32, 60, 80] dtype=int8> adding consumer <nng.Operation 'Relu_4;batchnorm_4/add_1' type=Add>
<nng.Tensor 'batchnorm_4/sub_npu' shape=[1, 32, 1, 1] dtype=int8> adding consumer <nng.Operation 'Relu_4;batchnorm_4/add_1' type=Add>
<nng.Tensor 'Relu_4;batchnorm_4/add_1' shape=[1, 32, 60, 80] dtype=int8> adding consumer <nng.Operation 'Pad_3_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_3_right_0_npu' shape=[1, 32, 60, 1] dtype=int8> adding consumer <nng.Operation 'Pad_3_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_20_npu' shape=[1, 32, 60, 80] dtype=int8> adding consumer <nng.Operation 'batchnorm_6/mul_1' type=Mul>
<nng.Tensor 'batchnorm_6/mul_npu' shape=[1, 32, 1, 1] dtype=int8> adding consumer <nng.Operation 'batchnorm_6/mul_1' type=Mul>
<nng.Tensor 'batchnorm_6/mul_1' shape=[1, 32, 60, 80] dtype=int8> adding consumer <nng.Operation 'Relu_6;batchnorm_6/add_1' type=Add>
<nng.Tensor 'batchnorm_6/sub_npu' shape=[1, 32, 1, 1] dtype=int8> adding consumer <nng.Operation 'Relu_6;batchnorm_6/add_1' type=Add>
<nng.Tensor 'Relu_6;batchnorm_6/add_1' shape=[1, 32, 60, 80] dtype=int8> adding consumer <nng.Operation 'Pad_4_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_4_right_0_npu' shape=[1, 32, 60, 1] dtype=int8> adding consumer <nng.Operation 'Pad_4_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_26_npu' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'batchnorm_8/mul_1' type=Mul>
<nng.Tensor 'batchnorm_8/mul_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'batchnorm_8/mul_1' type=Mul>
<nng.Tensor 'batchnorm_8/mul_1' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'Relu_8;batchnorm_8/add_1' type=Add>
<nng.Tensor 'batchnorm_8/sub_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'Relu_8;batchnorm_8/add_1' type=Add>
<nng.Tensor 'Relu_8;batchnorm_8/add_1' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'Pad_5_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_5_right_0_npu' shape=[1, 64, 30, 1] dtype=int8> adding consumer <nng.Operation 'Pad_5_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_32_npu' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'batchnorm_10/mul_1' type=Mul>
<nng.Tensor 'batchnorm_10/mul_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'batchnorm_10/mul_1' type=Mul>
<nng.Tensor 'batchnorm_10/mul_1' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'Relu_10;batchnorm_10/add_1' type=Add>
<nng.Tensor 'batchnorm_10/sub_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'Relu_10;batchnorm_10/add_1' type=Add>
<nng.Tensor 'Relu_10;batchnorm_10/add_1' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'Pad_6_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_6_right_0_npu' shape=[1, 64, 30, 1] dtype=int8> adding consumer <nng.Operation 'Pad_6_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_38_npu' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'batchnorm_12/mul_1' type=Mul>
<nng.Tensor 'batchnorm_12/mul_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'batchnorm_12/mul_1' type=Mul>
<nng.Tensor 'batchnorm_12/mul_1' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'Relu_12;batchnorm_12/add_1' type=Add>
<nng.Tensor 'batchnorm_12/sub_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'Relu_12;batchnorm_12/add_1' type=Add>
<nng.Tensor 'Relu_12;batchnorm_12/add_1' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'Pad_7_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_7_right_0_npu' shape=[1, 64, 30, 1] dtype=int8> adding consumer <nng.Operation 'Pad_7_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_44_npu' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'batchnorm_14/mul_1' type=Mul>
<nng.Tensor 'batchnorm_14/mul_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'batchnorm_14/mul_1' type=Mul>
<nng.Tensor 'batchnorm_14/mul_1' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'Relu_14;batchnorm_14/add_1' type=Add>
<nng.Tensor 'batchnorm_14/sub_npu' shape=[1, 64, 1, 1] dtype=int8> adding consumer <nng.Operation 'Relu_14;batchnorm_14/add_1' type=Add>
<nng.Tensor 'Relu_14;batchnorm_14/add_1' shape=[1, 64, 30, 40] dtype=int8> adding consumer <nng.Operation 'Pad_10_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_10_right_0_npu' shape=[1, 64, 30, 1] dtype=int8> adding consumer <nng.Operation 'Pad_10_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_64_npu' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'batchnorm_16/mul_1' type=Mul>
<nng.Tensor 'batchnorm_16/mul_npu' shape=[1, 128, 1, 1] dtype=int8> adding consumer <nng.Operation 'batchnorm_16/mul_1' type=Mul>
<nng.Tensor 'batchnorm_16/mul_1' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'Relu_18;batchnorm_16/add_1' type=Add>
<nng.Tensor 'batchnorm_16/sub_npu' shape=[1, 128, 1, 1] dtype=int8> adding consumer <nng.Operation 'Relu_18;batchnorm_16/add_1' type=Add>
<nng.Tensor 'Relu_18;batchnorm_16/add_1' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'Pad_11_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_11_right_0_npu' shape=[1, 128, 15, 1] dtype=int8> adding consumer <nng.Operation 'Pad_11_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_70_npu' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'batchnorm_18/mul_1' type=Mul>
<nng.Tensor 'batchnorm_18/mul_npu' shape=[1, 128, 1, 1] dtype=int8> adding consumer <nng.Operation 'batchnorm_18/mul_1' type=Mul>
<nng.Tensor 'batchnorm_18/mul_1' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'Relu_20;batchnorm_18/add_1' type=Add>
<nng.Tensor 'batchnorm_18/sub_npu' shape=[1, 128, 1, 1] dtype=int8> adding consumer <nng.Operation 'Relu_20;batchnorm_18/add_1' type=Add>
<nng.Tensor 'Relu_20;batchnorm_18/add_1' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'Pad_12_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_12_right_0_npu' shape=[1, 128, 15, 1] dtype=int8> adding consumer <nng.Operation 'Pad_12_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_76_npu' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'batchnorm_20/mul_1' type=Mul>
<nng.Tensor 'batchnorm_20/mul_npu' shape=[1, 128, 1, 1] dtype=int8> adding consumer <nng.Operation 'batchnorm_20/mul_1' type=Mul>
<nng.Tensor 'batchnorm_20/mul_1' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'Relu_22;batchnorm_20/add_1' type=Add>
<nng.Tensor 'batchnorm_20/sub_npu' shape=[1, 128, 1, 1] dtype=int8> adding consumer <nng.Operation 'Relu_22;batchnorm_20/add_1' type=Add>
<nng.Tensor 'Relu_22;batchnorm_20/add_1' shape=[1, 128, 15, 20] dtype=int8> adding consumer <nng.Operation 'Pad_13_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_13_right_0_npu' shape=[1, 128, 15, 1] dtype=int8> adding consumer <nng.Operation 'Pad_13_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_78_npu' shape=[1, 17, 22, 128] dtype=int8> adding consumer <nng.Operation 'Relu_23;Add_6;depthwise_14;depthwise_12;Const_44' type=DepthwiseConv2DBias>
<nng.Tensor 'depthwise_12_reshape_npu' shape=[3, 3, 1, 128] dtype=int8> adding consumer <nng.Operation 'Relu_23;Add_6;depthwise_14;depthwise_12;Const_44' type=DepthwiseConv2DBias>
<nng.Tensor 'Const_44_reshape_npu' shape=[128] dtype=int32> adding consumer <nng.Operation 'Relu_23;Add_6;depthwise_14;depthwise_12;Const_44' type=DepthwiseConv2DBias>
<nng.Tensor 'Relu_23;Add_6;depthwise_14;depthwise_12;Const_44' shape=[1, 15, 20, 128] dtype=int8> adding consumer <nng.Operation 'Add_7;convolution_17;convolution_13;Const_42' type=Conv2DBias>
<nng.Tensor 'convolution_13_reshape_npu' shape=[1, 1, 128, 4] dtype=int8> adding consumer <nng.Operation 'Add_7;convolution_17;convolution_13;Const_42' type=Conv2DBias>
<nng.Tensor 'Const_42_reshape_npu' shape=[4] dtype=int32> adding consumer <nng.Operation 'Add_7;convolution_17;convolution_13;Const_42' type=Conv2DBias>
<nng.Tensor 'Add_7;convolution_17;convolution_13;Const_42' shape=[1, 600, 2] dtype=int8> adding consumer <nng.Operation 'concat_501_avgpool' type=AvgPool>
<nng.Tensor 'transpose_96_npu' shape=[1, 256, 8, 10] dtype=int8> adding consumer <nng.Operation 'batchnorm_22/mul_1' type=Mul>
<nng.Tensor 'batchnorm_22/mul_npu' shape=[1, 256, 1, 1] dtype=int8> adding consumer <nng.Operation 'batchnorm_22/mul_1' type=Mul>
<nng.Tensor 'batchnorm_22/mul_1' shape=[1, 256, 8, 10] dtype=int8> adding consumer <nng.Operation 'Relu_26;batchnorm_22/add_1' type=Add>
<nng.Tensor 'batchnorm_22/sub_npu' shape=[1, 256, 1, 1] dtype=int8> adding consumer <nng.Operation 'Relu_26;batchnorm_22/add_1' type=Add>
<nng.Tensor 'Relu_26;batchnorm_22/add_1' shape=[1, 256, 8, 10] dtype=int8> adding consumer <nng.Operation 'Pad_16_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_16_right_0_npu' shape=[1, 256, 8, 1] dtype=int8> adding consumer <nng.Operation 'Pad_16_concat2_avgpool' type=AvgPool>
<nng.Tensor 'Relu_28;batchnorm_24/add_1_cpu' shape=[1, 256, 8, 10] dtype=int8> adding consumer <nng.Operation 'Pad_17_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_17_right_0_npu' shape=[1, 256, 8, 1] dtype=int8> adding consumer <nng.Operation 'Pad_17_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_104_npu' shape=[1, 10, 12, 256] dtype=int8> adding consumer <nng.Operation 'Relu_29;Add_12;convolution_20;depthwise_16;Const_16' type=DepthwiseConv2DBias>
<nng.Tensor 'depthwise_16_reshape_npu' shape=[3, 3, 1, 256] dtype=int8> adding consumer <nng.Operation 'Relu_29;Add_12;convolution_20;depthwise_16;Const_16' type=DepthwiseConv2DBias>
<nng.Tensor 'Const_16_reshape_npu' shape=[256] dtype=int32> adding consumer <nng.Operation 'Relu_29;Add_12;convolution_20;depthwise_16;Const_16' type=DepthwiseConv2DBias>
<nng.Tensor 'Relu_29;Add_12;convolution_20;depthwise_16;Const_16' shape=[1, 8, 10, 256] dtype=int8> adding consumer <nng.Operation 'Add_13;convolution_17;Const_14' type=Conv2DBias>
<nng.Tensor 'convolution_17_reshape_npu' shape=[1, 1, 256, 4] dtype=int8> adding consumer <nng.Operation 'Add_13;convolution_17;Const_14' type=Conv2DBias>
<nng.Tensor 'Const_14_reshape_npu' shape=[4] dtype=int32> adding consumer <nng.Operation 'Add_13;convolution_17;Const_14' type=Conv2DBias>
<nng.Tensor 'Add_13;convolution_17;Const_14' shape=[1, 160, 2] dtype=int8> adding consumer <nng.Operation 'concat_502_avgpool' type=AvgPool>
<nng.Tensor 'transpose_119_npu' shape=[1, 64, 8, 10] dtype=int8> adding consumer <nng.Operation 'Pad_19_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_19_right_0_npu' shape=[1, 64, 8, 1] dtype=int8> adding consumer <nng.Operation 'Pad_19_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_125_npu' shape=[1, 256, 4, 5] dtype=int8> adding consumer <nng.Operation 'Pad_20_concat1_avgpool' type=AvgPool>
<nng.Tensor 'Pad_20_right_0_npu' shape=[1, 256, 4, 1] dtype=int8> adding consumer <nng.Operation 'Pad_20_concat2_avgpool' type=AvgPool>
<nng.Tensor 'transpose_127_npu' shape=[1, 6, 7, 256] dtype=int8> adding consumer <nng.Operation 'Add_21;convolution_8;convolution_21;Const_2' type=Conv2DBias>
<nng.Tensor 'convolution_21_reshape_npu' shape=[3, 3, 256, 6] dtype=int8> adding consumer <nng.Operation 'Add_21;convolution_8;convolution_21;Const_2' type=Conv2DBias>
<nng.Tensor 'Const_2_reshape_npu' shape=[6] dtype=int32> adding consumer <nng.Operation 'Add_21;convolution_8;convolution_21;Const_2' type=Conv2DBias>
<nng.Tensor 'Add_21;convolution_8;convolution_21;Const_2' shape=[1, 60, 2] dtype=int8> adding consumer <nng.Operation 'concat_503_avgpool' type=AvgPool>

Network summary for lightface_slim_quant
Accelerator configuration               Ethos_U65_256
System configuration                 internal-default
Memory mode                          internal-default
Accelerator clock                                1000 MHz
Design peak SRAM bandwidth                      16.00 GB/s
Design peak DRAM bandwidth                       3.75 GB/s

Total SRAM used                                375.00 KiB
Total DRAM used                               2900.75 KiB

CPU operators = 7 (3.5%)
NPU operators = 194 (96.5%)

Average SRAM bandwidth                           0.21 GB/s
Input   SRAM bandwidth                          10.39 MB/batch
Weight  SRAM bandwidth                           1.34 MB/batch
Output  SRAM bandwidth                           0.00 MB/batch
Total   SRAM bandwidth                          11.77 MB/batch
Total   SRAM bandwidth            per input     11.77 MB/inference (batch size 1)

Average DRAM bandwidth                           0.82 GB/s
Input   DRAM bandwidth                          20.63 MB/batch
Weight  DRAM bandwidth                           0.28 MB/batch
Output  DRAM bandwidth                          23.72 MB/batch
Total   DRAM bandwidth                          44.64 MB/batch
Total   DRAM bandwidth            per input     44.64 MB/inference (batch size 1)

Neural network macs                          87839996 MACs/batch
Network Tops/s                                   0.00 Tops/s

NPU cycles                                   22449084 cycles/batch
SRAM Access cycles                            1623560 cycles/batch
DRAM Access cycles                           51542039 cycles/batch
On-chip Flash Access cycles                         0 cycles/batch
Off-chip Flash Access cycles                        0 cycles/batch
Total cycles                                 54743350 cycles/batch

Batch Inference time                54.74 ms,   18.27 inferences/s (batch size 1)

